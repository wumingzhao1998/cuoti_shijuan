import base64
import html
import io
import json
import os
import random
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

import requests
import streamlit as st
from docx import Document
from docx.shared import Inches
from streamlit.runtime.secrets import StreamlitSecretNotFoundError

# ç‰ˆæœ¬ä¿¡æ¯
VERSION = "1.0"

# é£ä¹¦å¤šç»´è¡¨æ ¼é…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
APP_TOKEN = os.getenv("FEISHU_APP_TOKEN", "NO9nbcpjraKeUCsSQkBcHL9gnhh")
TABLE_ID = os.getenv("FEISHU_TABLE_ID", "tblchSd315sqHTCt")


@st.cache_data(show_spinner=False, ttl=50 * 60)
def get_tenant_access_token(app_id: str, app_secret: str) -> str:
    """
    è·å– tenant_access_tokenï¼Œç”¨äºåç»­è°ƒç”¨å¤šç»´è¡¨æ ¼æ¥å£ã€‚
    """
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal/"
    resp = requests.post(url, json={"app_id": app_id, "app_secret": app_secret}, timeout=10)
    resp.raise_for_status()
    data = resp.json()
    if data.get("code") != 0:
        raise RuntimeError(f"è·å– tenant_access_token å¤±è´¥: {data}")
    return data["tenant_access_token"]


def fetch_records(token: str) -> List[Dict]:
    """
    æ‹‰å–è¡¨æ ¼å…¨éƒ¨è®°å½•ï¼Œè‡ªåŠ¨ç¿»é¡µã€‚
    """
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{TABLE_ID}/records/search"
    headers = {"Authorization": f"Bearer {token}"}
    page_token = None
    records: List[Dict] = []

    while True:
        payload: Dict[str, object] = {"page_size": 100}
        if page_token:
            payload["page_token"] = page_token

        resp = requests.post(url, headers=headers, json=payload, timeout=10)
        if not resp.ok:
            # è¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ï¼Œä¾¿äºæ’æŸ¥ token/table æƒé™é—®é¢˜
            try:
                detail = resp.json()
            except Exception:
                detail = resp.text
            raise RuntimeError(f"æ‹‰å–è®°å½•å¤±è´¥ HTTP {resp.status_code}: {detail}")
        data = resp.json()
        if data.get("code") != 0:
            raise RuntimeError(f"æ‹‰å–è®°å½•å¤±è´¥: {data}")

        items = data["data"].get("items", [])
        records.extend(items)
        page_token = data["data"].get("page_token")

        if not data["data"].get("has_more"):
            break

    return records


def normalize_to_list(value) -> List[str]:
    """
    å°†å•å€¼æˆ–åˆ—è¡¨å­—æ®µç»Ÿä¸€è½¬æˆå­—ç¬¦ä¸²åˆ—è¡¨ã€‚
    """
    if value is None:
        return []
    if isinstance(value, list):
        return [str(v) for v in value if v is not None]
    return [str(value)]


def normalize_text(value) -> str:
    """
    å°†å­—æ®µå®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼›åˆ—è¡¨ä¼šåˆå¹¶æˆæ¢è¡Œåˆ†éš”ã€‚
    """
    if value is None:
        return ""
    if isinstance(value, list):
        return "\n".join([str(v) for v in value if v is not None]).strip()
    return str(value).strip()


def is_image_file(name: str, mime: str = None) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶ï¼ˆæ ¹æ®MIMEç±»å‹æˆ–æ–‡ä»¶æ‰©å±•åï¼‰ã€‚
    """
    if mime:
        return mime.startswith("image/")
    if name:
        ext = name.lower().split(".")[-1] if "." in name else ""
        return ext in ["jpg", "jpeg", "png", "gif", "bmp", "webp", "svg"]
    return False


def extract_attachments(value) -> List[Dict]:
    """
    æå–é™„ä»¶åˆ—è¡¨ï¼Œå…¼å®¹é£ä¹¦å¤šç»´è¡¨æ ¼é™„ä»¶å­—æ®µå¸¸è§ç»“æ„ã€‚
    """
    if not isinstance(value, list):
        return []
    result = []
    for item in value:
        if not isinstance(item, dict):
            continue
        url = item.get("download_url") or item.get("tmp_url") or item.get("url")
        name = item.get("name") or item.get("file_name") or "é™„ä»¶"
        mime = item.get("mime_type") or item.get("type")
        result.append({"name": name, "url": url, "mime": mime})
    return result


def parse_records(raw_records: List[Dict]) -> List[Dict]:
    """
    å°†é£ä¹¦æ¥å£è¿”å›çš„è®°å½•è§£æä¸ºæ ‡å‡†ç»“æ„ã€‚
    """
    parsed = []
    for item in raw_records:
        fields = item.get("fields", {})
        subject = fields.get("å­¦ç§‘")
        knowledge_points = normalize_to_list(fields.get("çŸ¥è¯†ç‚¹"))
        reason_type = normalize_text(fields.get("ä¸ä¼š/åšé”™"))
        reason_detail = normalize_text(fields.get("ä¸ä¼š/åšé”™åŸå› "))
        
        # å¤„ç†"å»æ‰‹å†™"å­—æ®µï¼šä¼˜å…ˆä½œä¸ºé™„ä»¶å¤„ç†ï¼Œå¦åˆ™ä½œä¸ºæ–‡æœ¬
        handwriting_raw = fields.get("å»æ‰‹å†™")
        attachments = extract_attachments(handwriting_raw)
        handwriting_text = ""
        # å¦‚æœä¸æ˜¯é™„ä»¶åˆ—è¡¨ï¼Œåˆ™ä½œä¸ºæ–‡æœ¬å¤„ç†
        if not attachments:
            handwriting_text = normalize_text(handwriting_raw)
        
        # è·å–åˆ›å»ºæ—¶é—´ï¼ˆé£ä¹¦APIè¿”å›çš„æ˜¯æ¯«ç§’æ—¶é—´æˆ³ï¼‰
        created_time = item.get("created_time", 0)
        if isinstance(created_time, str):
            try:
                created_time = int(created_time)
            except ValueError:
                created_time = 0

        record_id = item.get("record_id") or ""

        parsed.append(
            {
                "record_id": record_id,
                "subject": subject,
                "knowledge_points": knowledge_points,
                "handwriting_text": handwriting_text,
                "reason_type": reason_type,
                "reason_detail": reason_detail,
                "attachments": attachments,
                "created_time": created_time,  # æ¯«ç§’æ—¶é—´æˆ³
            }
        )
    return parsed


# ----- é”™é¢˜ç»ƒä¹ ï¼šç»ƒä¹ è®°å½•è¡¨ä¸é€‰é¢˜ -----
# ç»ƒä¹ è®°å½•è¡¨å­—æ®µåï¼ˆä¸é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­æ–°å»ºè¡¨ä¸€è‡´ï¼‰
_P_FIELD_RID = "é”™é¢˜record_id"
_P_FIELD_LAST = "ä¸Šæ¬¡ç»ƒä¹ æ—¶é—´"
_P_FIELD_MASTERY = "æŒæ¡ç¨‹åº¦"
_P_FIELD_COUNT = "ç»ƒä¹ æ¬¡æ•°"
_P_FIELD_NEXT = "ä¸‹æ¬¡ç»ƒä¹ æ—¶é—´"


def _interval_days_for_mastered(n: int) -> int:
    """ã€Œä¼šã€æ—¶æŒ‰ç»ƒä¹ æ¬¡æ•°ç»™å‡ºçš„é—´éš”å¤©æ•°ã€‚"""
    return {1: 1, 2: 3, 3: 7, 4: 14}.get(n, 30)


def fetch_practice_records(token: str, practice_table_id: str) -> Dict[str, Dict[str, Any]]:
    """
    æ‹‰å–ç»ƒä¹ è®°å½•è¡¨å…¨éƒ¨è®°å½•ï¼Œè¿”å› é”™é¢˜record_id -> {practice_record_id, ä¸Šæ¬¡ç»ƒä¹ æ—¶é—´, æŒæ¡ç¨‹åº¦, ç»ƒä¹ æ¬¡æ•°, ä¸‹æ¬¡ç»ƒä¹ æ—¶é—´}ã€‚
    åŒä¸€é”™é¢˜è‹¥æœ‰å¤šæ¡ï¼Œä¿ç•™ ä¸Šæ¬¡ç»ƒä¹ æ—¶é—´ æœ€å¤§çš„ä¸€æ¡ã€‚
    """
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{practice_table_id}/records/search"
    headers = {"Authorization": f"Bearer {token}"}
    page_token = None
    out: Dict[str, Dict[str, Any]] = {}

    while True:
        payload: Dict[str, object] = {"page_size": 100}
        if page_token:
            payload["page_token"] = page_token
        resp = requests.post(url, headers=headers, json=payload, timeout=10)
        if not resp.ok:
            try:
                detail = resp.json()
            except Exception:
                detail = resp.text
            raise RuntimeError(f"æ‹‰å–ç»ƒä¹ è®°å½•å¤±è´¥ HTTP {resp.status_code}: {detail}")
        data = resp.json()
        if data.get("code") != 0:
            raise RuntimeError(f"æ‹‰å–ç»ƒä¹ è®°å½•å¤±è´¥: {data}")

        for item in data.get("data", {}).get("items", []):
            fields = item.get("fields", {})
            # å¤„ç† rid å­—æ®µï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
            rid_raw = fields.get(_P_FIELD_RID)
            if isinstance(rid_raw, list):
                rid = rid_raw[0].strip() if rid_raw and isinstance(rid_raw[0], str) else None
            else:
                rid = (rid_raw or "").strip() or None
            if not rid:
                continue
            try:
                last_ms = int(fields.get(_P_FIELD_LAST) or 0)
            except (TypeError, ValueError):
                last_ms = 0
            try:
                cnt = int(fields.get(_P_FIELD_COUNT) or 0)
            except (TypeError, ValueError):
                cnt = 0
            try:
                next_ms = int(fields.get(_P_FIELD_NEXT) or 0)
            except (TypeError, ValueError):
                next_ms = 0
            # å¤„ç† mastery å­—æ®µï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
            mastery_raw = fields.get(_P_FIELD_MASTERY)
            if isinstance(mastery_raw, list):
                mastery = mastery_raw[0].strip() if mastery_raw and isinstance(mastery_raw[0], str) else "ä¸ä¼š"
            else:
                mastery = (mastery_raw or "").strip() or "ä¸ä¼š"

            # è‹¥å·²å­˜åœ¨ï¼Œåªä¿ç•™ ä¸Šæ¬¡ç»ƒä¹ æ—¶é—´ æ›´å¤§çš„ä¸€æ¡
            if rid in out and (out[rid].get(_P_FIELD_LAST) or 0) >= last_ms:
                continue
            out[rid] = {
                "practice_record_id": item.get("record_id"),
                _P_FIELD_LAST: last_ms,
                _P_FIELD_MASTERY: mastery,
                _P_FIELD_COUNT: cnt,
                _P_FIELD_NEXT: next_ms,
            }

        page_token = data.get("data", {}).get("page_token")
        if not data.get("data", {}).get("has_more"):
            break

    return out


def create_practice_record(
    token: str,
    practice_table_id: str,
    question_record_id: str,
    mastery: str,
    count: int,
    next_ts_ms: int,
) -> Optional[str]:
    """åœ¨ç»ƒä¹ è®°å½•è¡¨ä¸­æ–°å»ºä¸€æ¡è®°å½•ï¼Œè¿”å›æ–°è®°å½•çš„ record_idã€‚"""
    now_ms = int(time.time() * 1000)
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{practice_table_id}/records"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    body = {
        "fields": {
            _P_FIELD_RID: question_record_id,
            _P_FIELD_LAST: now_ms,
            _P_FIELD_MASTERY: mastery,
            _P_FIELD_COUNT: count,
            _P_FIELD_NEXT: next_ts_ms,
        }
    }
    resp = requests.post(url, headers=headers, json=body, timeout=10)
    if not resp.ok:
        try:
            detail = resp.json()
        except Exception:
            detail = resp.text
        raise RuntimeError(f"åˆ›å»ºç»ƒä¹ è®°å½•å¤±è´¥ HTTP {resp.status_code}: {detail}")
    data = resp.json()
    if data.get("code") != 0:
        raise RuntimeError(f"åˆ›å»ºç»ƒä¹ è®°å½•å¤±è´¥: {data}")
    rec = (data.get("data") or {}).get("record") or {}
    return rec.get("record_id")


def update_practice_record(
    token: str,
    practice_table_id: str,
    practice_record_id: str,
    mastery: str,
    count: int,
    next_ts_ms: int,
) -> None:
    """æ›´æ–°ç»ƒä¹ è®°å½•è¡¨ä¸­ä¸€æ¡è®°å½•ã€‚"""
    now_ms = int(time.time() * 1000)
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{practice_table_id}/records/{practice_record_id}"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    body = {
        "fields": {
            _P_FIELD_LAST: now_ms,
            _P_FIELD_MASTERY: mastery,
            _P_FIELD_COUNT: count,
            _P_FIELD_NEXT: next_ts_ms,
        }
    }
    resp = requests.put(url, headers=headers, json=body, timeout=10)
    if not resp.ok:
        try:
            detail = resp.json()
        except Exception:
            detail = resp.text
        raise RuntimeError(f"æ›´æ–°ç»ƒä¹ è®°å½•å¤±è´¥ HTTP {resp.status_code}: {detail}")
    data = resp.json()
    if data.get("code") != 0:
        raise RuntimeError(f"æ›´æ–°ç»ƒä¹ è®°å½•å¤±è´¥: {data}")


def pick_next_question(
    filtered: List[Dict],
    practice_map: Dict[str, Dict[str, Any]],
    now_ms: int,
) -> Optional[Dict]:
    """
    ä»ç­›é€‰åçš„é”™é¢˜ä¸­é€‰ä¸€é“ï¼šä¸‹æ¬¡ç»ƒä¹ æ—¶é—´<=now ä¼˜å…ˆï¼Œå¦åˆ™å–ä¸‹æ¬¡ç»ƒä¹ æ—¶é—´æœ€æ—©ï¼›æ— ç»ƒä¹ è®°å½•è§†ä¸º 0 æœ€ä¼˜å…ˆã€‚
    """
    def next_ts(r: Dict) -> int:
        rid = (r.get("record_id") or "").strip()
        if not rid:
            return 0
        p = practice_map.get(rid)
        return int(p.get(_P_FIELD_NEXT, 0) or 0) if p else 0

    # è¿‡æ»¤ï¼šè‡³å°‘æœ‰ record_idã€ä¸” å»æ‰‹å†™ æˆ– é™„ä»¶ éç©º
    cand = [r for r in filtered if (r.get("record_id") or "").strip() and (r.get("handwriting_text") or r.get("attachments"))]
    if not cand:
        return None

    # æ’åºï¼šä¸‹æ¬¡ç»ƒä¹ æ—¶é—´ <= now çš„ä¼˜å…ˆï¼›å¦åˆ™æŒ‰ ä¸‹æ¬¡ç»ƒä¹ æ—¶é—´ å‡åº
    cand.sort(key=lambda r: (0 if next_ts(r) <= now_ms else 1, next_ts(r)))
    return cand[0]


def save_practice_feedback(
    token: str,
    practice_table_id: str,
    question_record_id: str,
    mastered: bool,
    practice_map: Dict[str, Dict[str, Any]],
) -> None:
    """
    æ ¹æ®ç”¨æˆ·é€‰æ‹© ä¼š/ä¸ä¼š å†™å…¥æˆ–æ›´æ–°ç»ƒä¹ è®°å½•ï¼Œå¹¶å°±åœ°æ›´æ–° practice_map ä»¥ä¾¿æœ¬åœ°é€‰é¢˜æ­£ç¡®ã€‚
    mastered=True è¡¨ç¤ºã€Œä¼šã€ï¼ŒFalse è¡¨ç¤ºã€Œä¸ä¼šã€ã€‚
    """
    now_ms = int(time.time() * 1000)
    p = practice_map.get(question_record_id) if question_record_id else None
    prev_count = int(p.get(_P_FIELD_COUNT, 0) or 0) if p else 0
    count = prev_count + 1
    mastery = "ä¼š" if mastered else "ä¸ä¼š"

    if mastered:
        days = _interval_days_for_mastered(count)
        next_ts_ms = now_ms + days * 24 * 60 * 60 * 1000
    else:
        next_ts_ms = now_ms + 5 * 60 * 1000  # +5 åˆ†é’Ÿ

    if p and p.get("practice_record_id"):
        update_practice_record(token, practice_table_id, p["practice_record_id"], mastery, count, next_ts_ms)
        p[_P_FIELD_LAST] = now_ms
        p[_P_FIELD_MASTERY] = mastery
        p[_P_FIELD_COUNT] = count
        p[_P_FIELD_NEXT] = next_ts_ms
    else:
        new_id = create_practice_record(token, practice_table_id, question_record_id, mastery, count, next_ts_ms)
        practice_map[question_record_id] = {
            "practice_record_id": new_id,
            _P_FIELD_LAST: now_ms,
            _P_FIELD_MASTERY: mastery,
            _P_FIELD_COUNT: count,
            _P_FIELD_NEXT: next_ts_ms,
        }


def _load_image_bytes_for_display(url: str, token: str) -> Optional[bytes]:
    """ä¸‹è½½é™„ä»¶å›¾ç‰‡ç”¨äº Streamlit å±•ç¤ºï¼Œæ”¯æŒé£ä¹¦ä¸´æ—¶ JSONã€‚"""
    if not url or not token:
        return None
    try:
        headers = {"Authorization": f"Bearer {token}"}
        r = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        if not r.ok:
            return None
        ct = (r.headers.get("Content-Type") or "").lower()
        if "application/json" in ct:
            try:
                j = r.json()
                if isinstance(j, dict) and j.get("code") == 0:
                    d = j.get("data", {})
                    u = None
                    tmp = d.get("tmp_download_urls") or []
                    if tmp and isinstance(tmp, list) and tmp:
                        u = tmp[0].get("tmp_download_url") if isinstance(tmp[0], dict) else None
                    if not u:
                        u = d.get("tmp_download_url") or d.get("download_url")
                    if u:
                        r2 = requests.get(u, headers=headers, timeout=15, allow_redirects=True)
                        if r2.ok:
                            return r2.content
            except Exception:
                pass
        return r.content if r.content else None
    except Exception:
        return None


def render_question_streamlit(record: Dict, token: str) -> None:
    """åœ¨ Streamlit ä¸­æ¸²æŸ“ä¸€é“é¢˜çš„æ–‡æœ¬ä¸å›¾ç‰‡ã€‚"""
    t = (record.get("handwriting_text") or "").strip()
    if t:
        st.markdown(t)
    for att in (record.get("attachments") or []):
        if not is_image_file(att.get("name"), att.get("mime")):
            continue
        url = att.get("url")
        raw = _load_image_bytes_for_display(url, token)
        if raw:
            try:
                st.image(io.BytesIO(raw))
            except Exception:
                pass


def safe_get_secret(key: str):
    """
    å®‰å…¨è¯»å– st.secretsï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. ç›´æ¥æ ¼å¼: KEY = "value"
    2. åµŒå¥—æ ¼å¼: [secrets] ä¸‹çš„ KEY = "value"
    """
    try:
        # æ–¹å¼1: ç›´æ¥è®¿é—®
        value = st.secrets.get(key)
        if value is not None and value != "":
            return value
    except:
        pass
    
    try:
        # æ–¹å¼2: ä» [secrets] åµŒå¥—ç»“æ„è¯»å–
        if "secrets" in st.secrets:
            value = st.secrets["secrets"].get(key)
            if value is not None and value != "":
                return value
    except:
        pass
    
    return None


def get_config_file_path() -> Path:
    """
    è·å–é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆåœ¨é¡¹ç›®ç›®å½•ä¸‹çš„ .feishu_config.jsonï¼‰ã€‚
    """
    return Path(__file__).parent / ".feishu_config.json"


def load_config() -> Dict[str, Optional[str]]:
    """
    ä»æœ¬åœ°é…ç½®æ–‡ä»¶åŠ è½½å‡­æ®ã€‚
    """
    config_file = get_config_file_path()
    if config_file.exists():
        try:
            with open(config_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_config(app_id: str, app_secret: str) -> None:
    """
    ä¿å­˜å‡­æ®åˆ°æœ¬åœ°é…ç½®æ–‡ä»¶ã€‚
    æ³¨æ„ï¼šåœ¨ Streamlit Cloud ç­‰åªè¯»æ–‡ä»¶ç³»ç»Ÿä¸Šï¼Œæ­¤æ“ä½œä¼šé™é»˜å¤±è´¥ã€‚
    """
    config_file = get_config_file_path()
    try:
        config = {"FEISHU_APP_ID": app_id, "FEISHU_APP_SECRET": app_secret}
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2)
        # è®¾ç½®æ–‡ä»¶æƒé™ï¼ˆä»…æ‰€æœ‰è€…å¯è¯»å†™ï¼‰
        if os.name != "nt":  # éWindowsç³»ç»Ÿ
            os.chmod(config_file, 0o600)
    except (IOError, OSError, PermissionError):
        # åœ¨ Streamlit Cloud ç­‰åªè¯»æ–‡ä»¶ç³»ç»Ÿä¸Šï¼Œä¿å­˜å¤±è´¥æ˜¯æ­£å¸¸çš„
        # é…ç½®åº”é€šè¿‡ç¯å¢ƒå˜é‡æˆ– st.secrets æä¾›
        pass
    except Exception:
        pass  # å…¶ä»–é”™è¯¯ä¹Ÿé™é»˜å¤„ç†


def build_doc(subjects: List[str], selections: Dict[str, List[Dict]], token: str) -> bytes:
    """
    æ ¹æ®é€‰æ‹©ç”Ÿæˆ Word æ–‡æ¡£äºŒè¿›åˆ¶å†…å®¹ã€‚
    """
    doc = Document()
    title = "ã€".join(subjects) if subjects else "é”™é¢˜"
    doc.add_heading(f"{title} é”™é¢˜ä¸“é¡¹è®­ç»ƒ", 0)

    for kp, questions in selections.items():
        # è·³è¿‡ç©ºåˆ—è¡¨ï¼ˆç”Ÿæˆå¤±è´¥çš„é¢˜ç›®ï¼‰
        if not questions:
            continue
        doc.add_heading(kp, level=1)
        for idx, q in enumerate(questions, start=1):
            # é¢˜ç›®å†…å®¹ï¼šä¼˜å…ˆä½¿ç”¨é™„ä»¶ï¼ˆå›¾ç‰‡ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨æ–‡æœ¬
            attachments = q.get("attachments") or []
            handwriting_text = q.get("handwriting_text", "").strip()
            
            if attachments:
                # æœ‰é™„ä»¶ï¼Œä½¿ç”¨ List Number ç¼–å·ï¼›ç¬¬ä¸€æ®µå†…å®¹æ”¾å…¥ paraï¼Œé¿å…ç©ºç¼–å·
                para = doc.add_paragraph(style="List Number")
                first = True

                for att in attachments:
                    url = att.get("url")
                    name = att.get("name") or "é™„ä»¶"
                    mime = att.get("mime")
                    if not url:
                        continue

                    is_image = is_image_file(name, mime)

                    if not is_image:
                        text = f"é™„ä»¶ï¼š{name}ï¼ˆéå›¾ç‰‡ï¼Œä¸‹è½½é“¾æ¥ï¼š{url}ï¼‰"
                        if first:
                            r = para.add_run(text)
                            r.italic = True
                            first = False
                        else:
                            p = doc.add_paragraph(text)
                            if p.runs:
                                p.runs[0].italic = True
                        continue

                    try:
                        headers = {"Authorization": f"Bearer {token}"}
                        resp = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
                        if not resp.ok:
                            text = f"[é™„ä»¶ä¸‹è½½å¤±è´¥] {name} - HTTP {resp.status_code}"
                            if first:
                                para.add_run(text)
                                first = False
                            else:
                                doc.add_paragraph(text)
                            continue

                        content_type = resp.headers.get("Content-Type", "").lower()
                        image_data = None

                        if "application/json" in content_type:
                            try:
                                json_data = resp.json()
                                if isinstance(json_data, dict) and json_data.get("code") == 0:
                                    data = json_data.get("data", {})
                                    tmp_urls = data.get("tmp_download_urls", [])
                                    if tmp_urls and isinstance(tmp_urls, list) and len(tmp_urls) > 0:
                                        real_url = tmp_urls[0].get("tmp_download_url") if isinstance(tmp_urls[0], dict) else None
                                    else:
                                        real_url = data.get("tmp_download_url") or data.get("download_url") or json_data.get("download_url")

                                    if real_url:
                                        resp2 = requests.get(real_url, headers=headers, timeout=15, allow_redirects=True)
                                        if resp2.ok:
                                            image_data = resp2.content
                                        else:
                                            text = f"[é™„ä»¶ä¸‹è½½å¤±è´¥] {name} - HTTP {resp2.status_code}"
                                            if first:
                                                para.add_run(text)
                                                first = False
                                            else:
                                                doc.add_paragraph(text)
                                            continue
                                    else:
                                        text = f"[æ— æ³•è·å–é™„ä»¶ä¸‹è½½åœ°å€] {name}"
                                        if first:
                                            para.add_run(text)
                                            first = False
                                        else:
                                            doc.add_paragraph(text)
                                        continue
                            except (ValueError, KeyError, TypeError):
                                image_data = resp.content
                        else:
                            image_data = resp.content

                        if image_data:
                            try:
                                image_stream = io.BytesIO(image_data)
                                if first:
                                    run = para.add_run()
                                    run.add_picture(image_stream, width=Inches(5.5))
                                    first = False
                                else:
                                    doc.add_picture(image_stream, width=Inches(5.5))
                            except Exception as img_exc:  # noqa: BLE001
                                text = f"é™„ä»¶ï¼š{name}ï¼ˆå›¾ç‰‡æ’å…¥å¤±è´¥ï¼š{img_exc}ï¼‰"
                                if first:
                                    r = para.add_run(text)
                                    r.italic = True
                                    first = False
                                else:
                                    p = doc.add_paragraph(text)
                                    if p.runs:
                                        p.runs[0].italic = True
                        else:
                            text = f"[é™„ä»¶å¤„ç†å¤±è´¥] {name}"
                            if first:
                                para.add_run(text)
                                first = False
                            else:
                                doc.add_paragraph(text)
                    except Exception as exc:  # noqa: BLE001
                        text = f"[é™„ä»¶å¤„ç†å¼‚å¸¸] {name}: {exc}"
                        if first:
                            para.add_run(text)
                            first = False
                        else:
                            doc.add_paragraph(text)
            elif handwriting_text:
                # æ²¡æœ‰é™„ä»¶ä½†æœ‰æ–‡æœ¬ï¼Œæ˜¾ç¤ºæ–‡æœ¬
                para = doc.add_paragraph(style="List Number")
                para.add_run(handwriting_text)
            else:
                # æ—¢æ— é™„ä»¶ä¹Ÿæ— æ–‡æœ¬
                para = doc.add_paragraph(style="List Number")
                para.add_run("ï¼ˆæ— é¢˜å¹²ï¼‰")
            
            # è¿½åŠ å¤‡æ³¨ä¿¡æ¯ï¼Œä¾¿äºå›é¡¾é”™å› 
            if q.get("reason_type") or q.get("reason_detail"):
                note = f"é”™å› ï¼š{q.get('reason_type') or ''} {q.get('reason_detail') or ''}".strip()
                if note.startswith("é”™å› ï¼š"):
                    doc.add_paragraph(note).italic = True

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()


def build_html(subjects: List[str], selections: Dict[str, List[Dict]], token: str) -> str:
    """
    æ ¹æ®é€‰æ‹©ç”Ÿæˆ HTML æ–‡æ¡£å†…å®¹ã€‚
    """
    title = "ã€".join(subjects) if subjects else "é”™é¢˜"
    
    html_parts = [
        "<!DOCTYPE html>",
        "<html lang='zh-CN'>",
        "<head>",
        "    <meta charset='UTF-8'>",
        "    <meta name='viewport' content='width=device-width, initial-scale=1.0'>",
        f"    <title>{title} é”™é¢˜ä¸“é¡¹è®­ç»ƒ</title>",
        "    <style>",
        "        body { font-family: 'Microsoft YaHei', Arial, sans-serif; line-height: 1.6; padding: 20px; max-width: 1200px; margin: 0 auto; }",
        "        h1 { color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }",
        "        h2 { color: #555; margin-top: 30px; border-left: 5px solid #2196F3; padding-left: 15px; }",
        "        .question { margin: 20px 0; padding: 15px; background: #f9f9f9; border-radius: 5px; }",
        "        .question-number { font-weight: bold; color: #2196F3; margin-right: 10px; }",
        "        .question-content { margin: 10px 0; }",
        "        .question-content img { max-width: 100%; height: auto; margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; }",
        "        .reason { font-style: italic; color: #666; margin-top: 10px; padding-left: 20px; }",
        "        .error-note { color: #ff9800; font-size: 0.9em; }",
        "    </style>",
        "</head>",
        "<body>",
        f"    <h1>{title} é”™é¢˜ä¸“é¡¹è®­ç»ƒ</h1>",
    ]
    
    for kp, questions in selections.items():
        # è·³è¿‡ç©ºåˆ—è¡¨ï¼ˆç”Ÿæˆå¤±è´¥çš„é¢˜ç›®ï¼‰
        if not questions:
            continue
        html_parts.append(f"    <h2>{kp}</h2>")
        
        for idx, q in enumerate(questions, start=1):
            html_parts.append("    <div class='question'>")
            html_parts.append(f"        <div class='question-number'>{idx}.</div>")
            html_parts.append("        <div class='question-content'>")
            
            attachments = q.get("attachments") or []
            handwriting_text = q.get("handwriting_text", "").strip()
            
            if attachments:
                # å¤„ç†é™„ä»¶ï¼ˆå›¾ç‰‡ï¼‰
                for att in attachments:
                    url = att.get("url")
                    name = att.get("name") or "é™„ä»¶"
                    mime = att.get("mime")
                    
                    if not url:
                        continue
                    
                    is_image = is_image_file(name, mime)
                    
                    if is_image:
                        try:
                            headers = {"Authorization": f"Bearer {token}"}
                            resp = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
                            
                            if resp.ok:
                                content_type = resp.headers.get("Content-Type", "").lower()
                                image_data = None
                                final_content_type = content_type
                                
                                # å¤„ç†JSONå“åº”
                                if "application/json" in content_type:
                                    try:
                                        json_data = resp.json()
                                        if isinstance(json_data, dict) and json_data.get("code") == 0:
                                            data = json_data.get("data", {})
                                            tmp_urls = data.get("tmp_download_urls", [])
                                            if tmp_urls and isinstance(tmp_urls, list) and len(tmp_urls) > 0:
                                                real_url = tmp_urls[0].get("tmp_download_url") if isinstance(tmp_urls[0], dict) else None
                                            else:
                                                real_url = data.get("tmp_download_url") or data.get("download_url")
                                            
                                            if real_url:
                                                resp2 = requests.get(real_url, headers=headers, timeout=15, allow_redirects=True)
                                                if resp2.ok:
                                                    image_data = resp2.content
                                                    final_content_type = resp2.headers.get("Content-Type", "image/png").lower()
                                    except Exception:
                                        pass
                                
                                if not image_data:
                                    image_data = resp.content
                                    final_content_type = content_type
                                
                                # è½¬æ¢ä¸ºbase64åµŒå…¥
                                img_base64 = base64.b64encode(image_data).decode('utf-8')
                                img_src = f"data:{final_content_type or 'image/png'};base64,{img_base64}"
                                html_parts.append(f"            <img src='{img_src}' alt='{name}' />")
                            else:
                                html_parts.append(f"            <p class='error-note'>[å›¾ç‰‡åŠ è½½å¤±è´¥] {name}</p>")
                        except Exception as exc:
                            html_parts.append(f"            <p class='error-note'>[å›¾ç‰‡åŠ è½½å¼‚å¸¸] {name}: {exc}</p>")
                    else:
                        html_parts.append(f"            <p>é™„ä»¶ï¼š<a href='{url}' target='_blank'>{name}</a></p>")
            elif handwriting_text:
                # æ˜¾ç¤ºæ–‡æœ¬å†…å®¹ï¼ˆè½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦ï¼‰
                escaped_text = html.escape(handwriting_text)
                html_parts.append(f"            <div>{escaped_text.replace(chr(10), '<br>')}</div>")
            else:
                html_parts.append("            <div>ï¼ˆæ— é¢˜å¹²ï¼‰</div>")
            
            html_parts.append("        </div>")
            
            # æ·»åŠ é”™å› å¤‡æ³¨
            if q.get("reason_type") or q.get("reason_detail"):
                reason = f"{q.get('reason_type') or ''} {q.get('reason_detail') or ''}".strip()
                if reason:
                    html_parts.append(f"        <div class='reason'>é”™å› ï¼š{html.escape(reason)}</div>")
            
            html_parts.append("    </div>")
    
    html_parts.extend([
        "</body>",
        "</html>"
    ])
    
    return "\n".join(html_parts)


def generate_similar_questions_with_llm(reference_question: Dict, count: int, api_key: str, api_base: str = None, model: str = None, token: str = None) -> List[str]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆç±»ä¼¼é¢˜ç›®ã€‚
    
    Args:
        reference_question: å‚è€ƒé¢˜ç›®ï¼ˆåŒ…å«handwriting_textæˆ–attachmentsï¼‰
        count: éœ€è¦ç”Ÿæˆçš„é¢˜ç›®æ•°é‡
        api_key: APIå¯†é’¥
        api_base: APIåŸºç¡€URLï¼ˆæ™ºè°±AI API Base URLï¼‰
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™æ ¹æ®api_baseè‡ªåŠ¨é€‰æ‹©ï¼‰
    
    Returns:
        ç”Ÿæˆçš„é¢˜ç›®åˆ—è¡¨
    """
    # æ„å»ºå‚è€ƒé¢˜ç›®çš„æ–‡æœ¬æè¿°
    ref_text = reference_question.get("handwriting_text", "").strip()
    attachments = reference_question.get("attachments", [])
    
    if not ref_text and not attachments:
        raise ValueError("å‚è€ƒé¢˜ç›®ä¸èƒ½ä¸ºç©º")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡é™„ä»¶
    image_attachments = [att for att in attachments if is_image_file(att.get("name", ""), att.get("mime"))]
    has_images = len(image_attachments) > 0
    
    # æ„å»ºæç¤ºè¯
    if ref_text:
        question_description = ref_text
    elif has_images:
        question_description = "ï¼ˆè¯·æŸ¥çœ‹å›¾ç‰‡ä¸­çš„é¢˜ç›®å†…å®¹ï¼‰"
    else:
        question_description = "[é¢˜ç›®å†…å®¹]"
    
    prompt_text = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•™å¸ˆï¼Œéœ€è¦åŸºäºå‚è€ƒé¢˜ç›®ç”Ÿæˆç±»ä¼¼çš„æ–°é¢˜ç›®ã€‚

å‚è€ƒé¢˜ç›®ï¼š{question_description}

è¯·ç”Ÿæˆ {count} é“ç±»ä¼¼çš„é¢˜ç›®ï¼Œè¦æ±‚ï¼š

1. **ä¿æŒæ ¸å¿ƒè¦ç´ ä¸€è‡´**ï¼š
   - ä¿æŒç›¸åŒçš„çŸ¥è¯†ç‚¹å’Œè§£é¢˜æ–¹æ³•
   - ä¿æŒç›¸åŒçš„é¢˜ç›®ç±»å‹ï¼ˆå¦‚é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€è®¡ç®—é¢˜ç­‰ï¼‰
   - ä¿æŒç›¸åŒçš„éš¾åº¦çº§åˆ«
   - å¦‚æœæ˜¯æ•°å­¦é¢˜ï¼Œä¿æŒç›¸åŒçš„è¿ç®—ç±»å‹å’Œå…¬å¼ç»“æ„

2. **åªæ”¹å˜å¯å˜è¦ç´ **ï¼š
   - å¯ä»¥æ”¹å˜å…·ä½“æ•°å­—ã€æ•°å€¼ï¼ˆå¦‚ï¼šæŠŠ"5+3"æ”¹ä¸º"7+4"ï¼‰
   - å¯ä»¥æ”¹å˜å…·ä½“çš„äººç‰©ã€ç‰©å“ã€åœºæ™¯åç§°
   - å¯ä»¥æ”¹å˜é¢˜ç›®çš„è¡¨è¿°æ–¹å¼ï¼Œä½†æ ¸å¿ƒæ„æ€ä¿æŒä¸€è‡´
   - ä¿æŒé¢˜ç›®çš„ç»“æ„å’Œè§£é¢˜æ­¥éª¤ä¸€è‡´

3. **è¾“å‡ºæ ¼å¼**ï¼š
   - æ¯é“é¢˜ç›®å•ç‹¬ä¸€è¡Œ
   - åªè¾“å‡ºé¢˜ç›®å†…å®¹ï¼Œä¸è¦ç¼–å·ï¼Œä¸è¦æ·»åŠ "é¢˜ç›®1"ã€"é¢˜ç›®2"ç­‰å‰ç¼€
   - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šè¯´æ˜
   - ç¡®ä¿æ¯é“é¢˜ç›®éƒ½æ˜¯å®Œæ•´ã€ç‹¬ç«‹ã€å¯ä»¥ç›´æ¥ä½¿ç”¨çš„

4. **è´¨é‡è¦æ±‚**ï¼š
   - é¢˜ç›®å¿…é¡»åˆç†ã€å¯è§£ï¼Œä¸èƒ½å‡ºç°é€»è¾‘é”™è¯¯
   - é¢˜ç›®å¿…é¡»ä¸åŸé¢˜éš¾åº¦ç›¸å½“
   - ä¸èƒ½ç”Ÿæˆå®Œå…¨ç›¸åŒçš„é¢˜ç›®ï¼Œä½†ä¹Ÿä¸èƒ½åç¦»å¤ªè¿œ
   - ç”Ÿæˆçš„é¢˜ç›®åº”è¯¥å¯ä»¥ç›´æ¥ç”¨äºç»ƒä¹ 

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè¦æ±‚ç”Ÿæˆ {count} é“ç±»ä¼¼é¢˜ç›®ï¼Œæ¯è¡Œä¸€é“ï¼š"""
    
    # é»˜è®¤ä½¿ç”¨æ™ºè°±AI GLM-4.6Vï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
    if not model:
        model = "glm-4.6v"
    
    # è°ƒç”¨æ™ºè°±AI API
    # æ™ºè°±AIçš„API URLæ ¼å¼
    if api_base and api_base.endswith("/chat/completions"):
        api_url = api_base
    else:
        api_url = (api_base or "https://open.bigmodel.cn/api/paas/v4").rstrip('/') + "/chat/completions"
    # æ™ºè°±AIçš„è®¤è¯æ ¼å¼
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€ï¼ˆå›¾ç‰‡è¾“å…¥ï¼‰
    model_lower = (model or "").lower()
    supports_vision = (
        "4.6v" in model_lower or 
        "glm-4-6v" in model_lower or 
        "glm-4.6v" in model_lower or
        "vision" in model_lower or 
        "4o" in model_lower or
        "gpt-4o" in model_lower
    )
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹
    if has_images and supports_vision:
        # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
        content_list = []
        image_added = False
        
        # æ·»åŠ å›¾ç‰‡ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        for img_att in image_attachments[:1]:  # åªä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡
            img_url = img_att.get("url")
            if img_url and token:
                # ä½¿ç”¨ç¼“å­˜è·å–å›¾ç‰‡
                cached = _get_cached_image_base64(img_url, token)
                if cached:
                    img_base64, img_mime = cached
                    content_list.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{img_mime};base64,{img_base64}"
                        }
                    })
                    image_added = True
        
        # æ·»åŠ æ–‡æœ¬æç¤º
        content_list.append({
            "type": "text",
            "text": prompt_text
        })
        
        # å¦‚æœæˆåŠŸæ·»åŠ äº†å›¾ç‰‡ï¼Œä½¿ç”¨å¤šæ¨¡æ€æ¶ˆæ¯ï¼›å¦åˆ™å›é€€åˆ°çº¯æ–‡æœ¬
        if image_added:
            messages = [{"role": "user", "content": content_list}]
        else:
            # å›¾ç‰‡æ·»åŠ å¤±è´¥ï¼Œå¦‚æœæœ‰æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨æ–‡æœ¬ï¼›å¦åˆ™æŠ›å‡ºé”™è¯¯
            if ref_text:
                # æœ‰æ–‡æœ¬å†…å®¹ï¼Œé‡æ–°æ„å»ºæç¤ºè¯ï¼ˆä¸æåŠå›¾ç‰‡ï¼‰
                fallback_prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•™å¸ˆï¼Œéœ€è¦åŸºäºå‚è€ƒé¢˜ç›®ç”Ÿæˆç±»ä¼¼çš„æ–°é¢˜ç›®ã€‚

å‚è€ƒé¢˜ç›®ï¼š{ref_text}

è¯·ç”Ÿæˆ {count} é“ç±»ä¼¼çš„é¢˜ç›®ï¼Œè¦æ±‚ï¼š

1. **ä¿æŒæ ¸å¿ƒè¦ç´ ä¸€è‡´**ï¼š
   - ä¿æŒç›¸åŒçš„çŸ¥è¯†ç‚¹å’Œè§£é¢˜æ–¹æ³•
   - ä¿æŒç›¸åŒçš„é¢˜ç›®ç±»å‹ï¼ˆå¦‚é€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€è®¡ç®—é¢˜ç­‰ï¼‰
   - ä¿æŒç›¸åŒçš„éš¾åº¦çº§åˆ«
   - å¦‚æœæ˜¯æ•°å­¦é¢˜ï¼Œä¿æŒç›¸åŒçš„è¿ç®—ç±»å‹å’Œå…¬å¼ç»“æ„

2. **åªæ”¹å˜å¯å˜è¦ç´ **ï¼š
   - å¯ä»¥æ”¹å˜å…·ä½“æ•°å­—ã€æ•°å€¼ï¼ˆå¦‚ï¼šæŠŠ"5+3"æ”¹ä¸º"7+4"ï¼‰
   - å¯ä»¥æ”¹å˜å…·ä½“çš„äººç‰©ã€ç‰©å“ã€åœºæ™¯åç§°
   - å¯ä»¥æ”¹å˜é¢˜ç›®çš„è¡¨è¿°æ–¹å¼ï¼Œä½†æ ¸å¿ƒæ„æ€ä¿æŒä¸€è‡´
   - ä¿æŒé¢˜ç›®çš„ç»“æ„å’Œè§£é¢˜æ­¥éª¤ä¸€è‡´

3. **è¾“å‡ºæ ¼å¼**ï¼š
   - æ¯é“é¢˜ç›®å•ç‹¬ä¸€è¡Œ
   - åªè¾“å‡ºé¢˜ç›®å†…å®¹ï¼Œä¸è¦ç¼–å·ï¼Œä¸è¦æ·»åŠ "é¢˜ç›®1"ã€"é¢˜ç›®2"ç­‰å‰ç¼€
   - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šè¯´æ˜
   - ç¡®ä¿æ¯é“é¢˜ç›®éƒ½æ˜¯å®Œæ•´ã€ç‹¬ç«‹ã€å¯ä»¥ç›´æ¥ä½¿ç”¨çš„

4. **è´¨é‡è¦æ±‚**ï¼š
   - é¢˜ç›®å¿…é¡»åˆç†ã€å¯è§£ï¼Œä¸èƒ½å‡ºç°é€»è¾‘é”™è¯¯
   - é¢˜ç›®å¿…é¡»ä¸åŸé¢˜éš¾åº¦ç›¸å½“
   - ä¸èƒ½ç”Ÿæˆå®Œå…¨ç›¸åŒçš„é¢˜ç›®ï¼Œä½†ä¹Ÿä¸èƒ½åç¦»å¤ªè¿œ
   - ç”Ÿæˆçš„é¢˜ç›®åº”è¯¥å¯ä»¥ç›´æ¥ç”¨äºç»ƒä¹ 

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè¦æ±‚ç”Ÿæˆ {count} é“ç±»ä¼¼é¢˜ç›®ï¼Œæ¯è¡Œä¸€é“ï¼š"""
                messages = [{"role": "user", "content": fallback_prompt}]
            else:
                # æ²¡æœ‰æ–‡æœ¬ä¹Ÿæ²¡æœ‰å›¾ç‰‡ï¼Œæ— æ³•ç”Ÿæˆé¢˜ç›®
                raise ValueError("é¢˜ç›®åŒ…å«å›¾ç‰‡ä½†å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œä¸”æ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œæ— æ³•ç”Ÿæˆç±»ä¼¼é¢˜ç›®ã€‚è¯·æ£€æŸ¥å›¾ç‰‡URLæˆ–ç½‘ç»œè¿æ¥ã€‚")
    else:
        # çº¯æ–‡æœ¬æ¶ˆæ¯
        messages = [{"role": "user", "content": prompt_text}]
    
    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=60)
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if not response.ok:
            # è·å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            try:
                error_detail = response.json()
                error_msg = f"APIé”™è¯¯ {response.status_code}: {error_detail}"
            except:
                error_msg = f"APIé”™è¯¯ {response.status_code}: {response.text[:200]}"
            
            # æ ¹æ®ä¸åŒé”™è¯¯ç æä¾›æ›´è¯¦ç»†çš„æç¤º
            if response.status_code == 400:
                error_msg += f"\nè¯·æ±‚URL: {api_url}\næ¨¡å‹: {model}\nè¯·æ£€æŸ¥æ¨¡å‹åç§°ã€API Keyå’Œè¯·æ±‚æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
            elif response.status_code == 401:
                error_msg += f"\nè¯·æ±‚URL: {api_url}\næ¨¡å‹: {model}\nâš ï¸ API Keyæ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥ï¼š\n1. API Keyæ˜¯å¦æ­£ç¡®\n2. API Keyæ˜¯å¦å·²è¿‡æœŸ\n3. API Keyæ˜¯å¦æœ‰è¶³å¤Ÿçš„æƒé™è®¿é—®è¯¥æ¨¡å‹"
            
            raise Exception(error_msg)
        
        response.raise_for_status()
        result = response.json()
        
        # æ£€æŸ¥å“åº”æ ¼å¼
        if "choices" not in result or not result["choices"]:
            raise Exception(f"APIå“åº”æ ¼å¼é”™è¯¯: {result}")
        
        # æå–ç”Ÿæˆçš„æ–‡æœ¬
        generated_text = result["choices"][0]["message"]["content"].strip()
        
        # æŒ‰è¡Œåˆ†å‰²ï¼Œè¿‡æ»¤ç©ºè¡Œ
        questions = [q.strip() for q in generated_text.split("\n") if q.strip()]
        
        # å¦‚æœç”Ÿæˆçš„æ•°é‡ä¸å¤Ÿï¼Œé‡å¤æœ€åä¸€é“é¢˜
        while len(questions) < count:
            questions.append(questions[-1] if questions else "ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰")
        
        # å¦‚æœç”Ÿæˆçš„æ•°é‡å¤ªå¤šï¼Œåªå–å‰countä¸ª
        return questions[:count]
    
    except Exception as e:
        # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†
        raise Exception(f"é¢˜ç›®ç”Ÿæˆå¤±è´¥: {str(e)}")


def _load_app_config():
    """åŠ è½½åº”ç”¨é…ç½®ï¼Œè¿”å› (app_id, app_secret, llm_api_key, llm_api_base, llm_model, config, is_streamlit_cloud)"""
    config = load_config()
    
    # æ£€æµ‹æ˜¯å¦åœ¨ Streamlit Cloud ä¸Šè¿è¡Œ
    try:
        _ = st.secrets
        is_streamlit_cloud = True
    except StreamlitSecretNotFoundError:
        is_streamlit_cloud = False
    except (AttributeError, RuntimeError, Exception):
        is_streamlit_cloud = False
    
    # è¯»å–é£ä¹¦é…ç½®
    env_app_id = os.getenv("FEISHU_APP_ID")
    env_app_secret = os.getenv("FEISHU_APP_SECRET")
    secret_app_id = safe_get_secret("FEISHU_APP_ID")
    secret_app_secret = safe_get_secret("FEISHU_APP_SECRET")
    config_app_id = config.get("FEISHU_APP_ID")
    config_app_secret = config.get("FEISHU_APP_SECRET")
    session_app_id = st.session_state.get("feishu_app_id")
    session_app_secret = st.session_state.get("feishu_app_secret")
    
    app_id = env_app_id or secret_app_id or config_app_id or session_app_id
    app_secret = env_app_secret or secret_app_secret or config_app_secret or session_app_secret
    
    # è¯»å–LLMé…ç½®
    llm_api_key = (
        os.getenv("LLM_API_KEY")
        or safe_get_secret("LLM_API_KEY")
        or config.get("LLM_API_KEY")
        or st.session_state.get("llm_api_key")
    )
    llm_api_base = "https://open.bigmodel.cn/api/paas/v4"  # å›ºå®šä½¿ç”¨æ™ºè°±AI
    llm_model = (
        os.getenv("LLM_MODEL")
        or safe_get_secret("LLM_MODEL")
        or config.get("LLM_MODEL")
        or st.session_state.get("llm_model")
        or "glm-4.6v"
    )
    
    return app_id, app_secret, llm_api_key, llm_api_base, llm_model, config, is_streamlit_cloud


def _check_feishu_credentials(app_id, app_secret, is_streamlit_cloud):
    """æ£€æŸ¥é£ä¹¦å‡­æ®ï¼Œå¦‚æœç¼ºå¤±åˆ™æ˜¾ç¤ºé…ç½®ç•Œé¢"""
    if not app_id or not app_secret:
        if is_streamlit_cloud:
            missing_items = []
            if not app_id:
                missing_items.append("FEISHU_APP_ID")
            if not app_secret:
                missing_items.append("FEISHU_APP_SECRET")
            st.error(f"âŒ é…ç½®ç¼ºå¤±ï¼š{', '.join(missing_items)}ï¼Œè¯·åœ¨ Streamlit Cloud Secrets ä¸­é…ç½®ã€‚")
            st.stop()
        else:
            st.info("è¯·è¾“å…¥é£ä¹¦åº”ç”¨å‡­æ®")
            app_id_input = st.text_input("FEISHU_APP_ID", value=app_id or "")
            app_secret_input = st.text_input("FEISHU_APP_SECRET", value=app_secret or "", type="password")
            if not app_id_input or not app_secret_input:
                st.stop()
            save_config(app_id_input, app_secret_input)
            st.session_state["feishu_app_id"] = app_id_input
            st.session_state["feishu_app_secret"] = app_secret_input
            return app_id_input, app_secret_input
    return app_id, app_secret


def _render_home_page():
    """æ¸²æŸ“ä¸»é¡µï¼šä¸¤ä¸ªå¤§æŒ‰é’®"""
    st.title("ğŸ“š é”™é¢˜æœ¬")
    st.caption(f"v{VERSION}")
    
    st.markdown("---")
    
    # ä½¿ç”¨å®¹å™¨åˆ›å»ºæ›´ç¾è§‚çš„æŒ‰é’®å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 20px;">
            <h2>ğŸ“</h2>
            <p>æ ¹æ®è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿å¤ä¹ é”™é¢˜</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("é”™é¢˜ç»ƒä¹ ", type="primary", use_container_width=True, key="home_practice_btn"):
            st.session_state["current_page"] = "practice"
            st.rerun()
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 20px;">
            <h2>ğŸ“„</h2>
            <p>é€‰æ‹©å­¦ç§‘å’ŒçŸ¥è¯†ç‚¹ç”Ÿæˆè¯•å·</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("ç”Ÿæˆè¯•å·", type="primary", use_container_width=True, key="home_exam_btn"):
            st.session_state["current_page"] = "exam"
            st.rerun()


# ==================== ç»ƒä¹ ä¼˜åŒ–ç›¸å…³å‡½æ•° ====================

def _get_today_str() -> str:
    """è·å–ä»Šå¤©çš„æ—¥æœŸå­—ç¬¦ä¸²"""
    return datetime.now().strftime("%Y-%m-%d")


def _init_daily_practice_tracking():
    """åˆå§‹åŒ–æ¯æ—¥ç»ƒä¹ è¿½è¸ªï¼Œæ¯å¤©é‡ç½®"""
    today = _get_today_str()
    if st.session_state.get("practice_date") != today:
        st.session_state["practiced_today"] = set()
        st.session_state["practice_date"] = today
        st.session_state["similar_cache"] = {}  # æ¯å¤©ä¹Ÿæ¸…ç©ºç¼“å­˜
        st.session_state["pregenerate_queue"] = []
        st.session_state["pregenerate_done"] = set()


def _mark_practiced_today(record_id: str):
    """æ ‡è®°æŸé¢˜ä»Šæ—¥å·²ç»ƒè¿‡"""
    if not record_id:
        return
    _init_daily_practice_tracking()
    practiced = st.session_state.get("practiced_today", set())
    practiced.add(record_id)
    st.session_state["practiced_today"] = practiced


def _is_practiced_today(record_id: str) -> bool:
    """æ£€æŸ¥æŸé¢˜ä»Šæ—¥æ˜¯å¦å·²ç»ƒè¿‡"""
    if not record_id:
        return False
    _init_daily_practice_tracking()
    return record_id in st.session_state.get("practiced_today", set())


def _filter_not_practiced_today(questions: List[Dict]) -> List[Dict]:
    """è¿‡æ»¤æ‰ä»Šæ—¥å·²ç»ƒè¿‡çš„é¢˜ç›®"""
    _init_daily_practice_tracking()
    practiced = st.session_state.get("practiced_today", set())
    return [q for q in questions if (q.get("record_id") or "").strip() not in practiced]


def _get_similar_from_cache(record_id: str) -> Optional[str]:
    """ä»ç¼“å­˜è·å–ç±»ä¼¼é¢˜"""
    if not record_id:
        return None
    cache = st.session_state.get("similar_cache", {})
    if record_id in cache and cache[record_id]:
        # å–å‡ºä¸€é“ï¼ˆä¸åˆ é™¤ï¼Œå› ä¸ºå¯èƒ½éœ€è¦ç¬¬äºŒé“ï¼‰
        return cache[record_id][0] if cache[record_id] else None
    return None


def _get_second_similar_from_cache(record_id: str) -> Optional[str]:
    """ä»ç¼“å­˜è·å–ç¬¬äºŒé“ç±»ä¼¼é¢˜"""
    if not record_id:
        return None
    cache = st.session_state.get("similar_cache", {})
    if record_id in cache and len(cache[record_id]) >= 2:
        return cache[record_id][1]
    return None


def _add_to_similar_cache(record_id: str, similar_texts: List[str]):
    """æ·»åŠ ç±»ä¼¼é¢˜åˆ°ç¼“å­˜"""
    if not record_id or not similar_texts:
        return
    if "similar_cache" not in st.session_state:
        st.session_state["similar_cache"] = {}
    st.session_state["similar_cache"][record_id] = similar_texts


def _get_cached_image_base64(img_url: str, token: str) -> Optional[tuple]:
    """
    è·å–å›¾ç‰‡çš„base64ç¼–ç ï¼Œä¼˜å…ˆä»ç¼“å­˜è¯»å–
    è¿”å› (base64_data, mime_type) æˆ– None
    """
    if not img_url:
        return None
    
    # æ£€æŸ¥ç¼“å­˜
    if "image_cache" not in st.session_state:
        st.session_state["image_cache"] = {}
    
    cache = st.session_state["image_cache"]
    if img_url in cache:
        return cache[img_url]
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œä¸‹è½½å›¾ç‰‡
    try:
        img_headers = {"Authorization": f"Bearer {token}"}
        img_resp = requests.get(img_url, headers=img_headers, timeout=15, allow_redirects=True)
        
        if img_resp.ok:
            content_type = img_resp.headers.get("Content-Type", "").lower()
            image_data = None
            
            if "application/json" in content_type:
                try:
                    json_data = img_resp.json()
                    if isinstance(json_data, dict) and json_data.get("code") == 0:
                        data = json_data.get("data", {})
                        tmp_urls = data.get("tmp_download_urls", [])
                        if tmp_urls and isinstance(tmp_urls, list) and len(tmp_urls) > 0:
                            real_url = tmp_urls[0].get("tmp_download_url") if isinstance(tmp_urls[0], dict) else None
                        else:
                            real_url = data.get("tmp_download_url") or data.get("download_url")
                        
                        if real_url:
                            img_resp2 = requests.get(real_url, headers=img_headers, timeout=15, allow_redirects=True)
                            if img_resp2.ok:
                                image_data = img_resp2.content
                                content_type = img_resp2.headers.get("Content-Type", "image/png").lower()
                except Exception:
                    pass
            
            if not image_data:
                image_data = img_resp.content
            
            if image_data and len(image_data) > 0:
                img_base64 = base64.b64encode(image_data).decode('utf-8')
                img_mime = content_type if content_type and "image" in content_type else "image/png"
                result = (img_base64, img_mime)
                cache[img_url] = result
                return result
    except Exception:
        pass
    
    return None


def _pregenerate_one_similar(question: Dict, llm_api_key: str, llm_api_base: str, llm_model: str, token: str) -> bool:
    """ä¸ºä¸€é“é¢˜é¢„ç”Ÿæˆç±»ä¼¼é¢˜ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    record_id = (question.get("record_id") or "").strip()
    if not record_id:
        return False
    
    # å·²ç»ç”Ÿæˆè¿‡åˆ™è·³è¿‡
    done = st.session_state.get("pregenerate_done", set())
    if record_id in done:
        return True
    
    try:
        # ç”Ÿæˆ2é“ç±»ä¼¼é¢˜ï¼ˆç¬¬ä¸€æ¬¡ä¸ä¼šå’Œç¬¬äºŒæ¬¡ä¸ä¼šå„ç”¨ä¸€é“ï¼‰
        texts = generate_similar_questions_with_llm(question, 2, llm_api_key, llm_api_base, llm_model, token)
        if texts:
            _add_to_similar_cache(record_id, texts)
            done.add(record_id)
            st.session_state["pregenerate_done"] = done
            return True
    except Exception:
        pass
    return False


def _get_pregenerate_progress() -> tuple:
    """è·å–é¢„ç”Ÿæˆè¿›åº¦ (å·²å®Œæˆ, æ€»æ•°)"""
    done = len(st.session_state.get("pregenerate_done", set()))
    queue = st.session_state.get("pregenerate_queue", [])
    total = len(queue)
    return (done, total)


def _render_practice_page(token, records, llm_api_key, llm_api_base, llm_model, config):
    """æ¸²æŸ“é”™é¢˜ç»ƒä¹ é¡µé¢"""
    # åˆå§‹åŒ–æ¯æ—¥ç»ƒä¹ è¿½è¸ª
    _init_daily_practice_tracking()
    
    # è¿”å›æŒ‰é’®
    if st.button("â† è¿”å›ä¸»é¡µ", key="practice_back"):
        # æ¸…ç†ç»ƒä¹ çŠ¶æ€
        for k in ("practice_current", "practice_origin", "practice_is_similar", "practice_similar_count", "practice_map", "practice_filtered", "practice_table_id", "pregenerate_queue", "pregenerate_done"):
            st.session_state.pop(k, None)
        st.session_state["current_page"] = "home"
        st.rerun()
    
    st.title("ğŸ“ é”™é¢˜ç»ƒä¹ ")
    st.caption("æ ¹æ®è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿æ™ºèƒ½å®‰æ’å¤ä¹ ï¼ˆé”™é¢˜åŸé¢˜æ¯å¤©åªå‡ºç°ä¸€æ¬¡ï¼‰")
    
    practice_table_id = (
        os.getenv("FEISHU_PRACTICE_TABLE_ID")
        or safe_get_secret("FEISHU_PRACTICE_TABLE_ID")
        or config.get("FEISHU_PRACTICE_TABLE_ID")
        or ""
    )
    
    if not practice_table_id:
        st.error(
            "é”™é¢˜ç»ƒä¹ éœ€è¦é…ç½® **FEISHU_PRACTICE_TABLE_ID**ï¼ˆç»ƒä¹ è®°å½•è¡¨çš„ table_idï¼‰ã€‚\n\n"
            "è¯·åœ¨ `.feishu_config.json` ä¸­é…ç½®ã€‚\n\n"
            "éœ€åœ¨åŒä¸€å¤šç»´è¡¨æ ¼ä¸‹æ–°å»ºä¸€å¼ è¡¨ï¼ŒåŒ…å«å­—æ®µï¼šé”™é¢˜record_idã€ä¸Šæ¬¡ç»ƒä¹ æ—¶é—´ã€æŒæ¡ç¨‹åº¦ã€ç»ƒä¹ æ¬¡æ•°ã€ä¸‹æ¬¡ç»ƒä¹ æ—¶é—´ã€‚"
        )
        return
    
    # å­¦ç§‘ç­›é€‰
    subjects = sorted({r["subject"] for r in records if r.get("subject")})
    selected_subjects = st.multiselect("é€‰æ‹©å­¦ç§‘", options=subjects, default=subjects, key="practice_subjects")
    filtered = [r for r in records if r.get("subject") in selected_subjects]
    
    # çŸ¥è¯†ç‚¹ç­›é€‰
    knowledge_options = sorted({kp for r in filtered for kp in r.get("knowledge_points") or []})
    selected_kp = st.multiselect("é€‰æ‹©çŸ¥è¯†ç‚¹", options=knowledge_options, default=knowledge_options, key="practice_kp")
    
    filtered_practice = [r for r in filtered if any(kp in (r.get("knowledge_points") or []) for kp in selected_kp)] if selected_kp else filtered
    
    st.markdown("---")
    
    # æ˜¾ç¤ºé¢„ç”Ÿæˆè¿›åº¦
    done_count, total_count = _get_pregenerate_progress()
    if total_count > 0:
        if done_count < total_count:
            st.caption(f"â³ æ­£åœ¨å‡†å¤‡ç±»ä¼¼é¢˜... ({done_count}/{total_count})")
        else:
            st.caption(f"âœ“ ç±»ä¼¼é¢˜å·²å°±ç»ª ({done_count}/{total_count})")
    
    def _go_next_practice() -> None:
        """è¿›å…¥ä¸‹ä¸€é“é¢˜ï¼Œå¹¶æ ‡è®°å½“å‰é¢˜å·²ç»ƒè¿‡"""
        # æ ‡è®°å½“å‰é¢˜ä»Šæ—¥å·²ç»ƒ
        cur = st.session_state.get("practice_current")
        if cur and not st.session_state.get("practice_is_similar"):
            rid = (cur.get("record_id") or "").strip()
            if rid:
                _mark_practiced_today(rid)
        
        pm = st.session_state.get("practice_map", {})
        pf = st.session_state.get("practice_filtered", [])
        
        # è¿‡æ»¤æ‰ä»Šæ—¥å·²ç»ƒè¿‡çš„é¢˜ç›®
        pf_available = _filter_not_practiced_today(pf)
        
        n = pick_next_question(pf_available, pm, int(time.time() * 1000))
        if n:
            st.session_state["practice_current"] = n
            st.session_state["practice_origin"] = None
            st.session_state["practice_is_similar"] = False
            st.session_state["practice_similar_count"] = 0
        else:
            for k in ("practice_current", "practice_origin", "practice_is_similar", "practice_similar_count"):
                st.session_state.pop(k, None)
            st.success("ğŸ‰ æœ¬è½®å¯å¤ä¹ çš„é¢˜ç›®å·²ç»ƒå®Œï¼")
    
    if st.session_state.get("practice_current"):
        cur = st.session_state["practice_current"]
        st.session_state.setdefault("practice_map", {})
        st.session_state.setdefault("practice_filtered", [])
        
        # æ˜¾ç¤ºé¢˜ç›®
        st.markdown("### å½“å‰é¢˜ç›®")
        if st.session_state.get("practice_is_similar"):
            st.caption("ğŸ“Œ ç±»ä¼¼é¢˜")
        
        render_question_streamlit(cur, token)
        
        st.markdown("---")
        st.markdown("**æŒæ¡äº†å—ï¼Ÿ**")
        
        col_a, col_b = st.columns(2)
        with col_a:
            if st.button("âœ“ ä¼šäº†", type="primary", use_container_width=True, key="practice_btn_yes"):
                is_sim = st.session_state.get("practice_is_similar", False)
                if not is_sim:
                    save_practice_feedback(
                        token,
                        st.session_state["practice_table_id"],
                        (cur.get("record_id") or "").strip(),
                        True,
                        st.session_state["practice_map"],
                    )
                _go_next_practice()
                st.rerun()
        
        with col_b:
            if st.button("âœ— ä¸ä¼š", use_container_width=True, key="practice_btn_no"):
                is_sim = st.session_state.get("practice_is_similar", False)
                orig = st.session_state.get("practice_origin")
                ptid = st.session_state.get("practice_table_id", "")
                pm = st.session_state.get("practice_map", {})
                
                if not is_sim:
                    # ç¬¬ä¸€æ¬¡ç‚¹å‡»"ä¸ä¼š"
                    rid = (cur.get("record_id") or "").strip()
                    save_practice_feedback(token, ptid, rid, False, pm)
                    st.session_state["practice_origin"] = cur
                    
                    # ä¼˜å…ˆä»ç¼“å­˜è·å–ç±»ä¼¼é¢˜
                    cached_similar = _get_similar_from_cache(rid)
                    if cached_similar:
                        st.session_state["practice_current"] = {"handwriting_text": cached_similar, "attachments": [], "record_id": ""}
                        st.session_state["practice_is_similar"] = True
                        st.session_state["practice_similar_count"] = 1
                        st.rerun()
                    elif llm_api_key:
                        # ç¼“å­˜æœªå‘½ä¸­ï¼Œå®æ—¶ç”Ÿæˆ
                        with st.spinner("æ­£åœ¨ç”Ÿæˆç±»ä¼¼é¢˜ç›®â€¦"):
                            try:
                                texts = generate_similar_questions_with_llm(cur, 2, llm_api_key, llm_api_base, llm_model, token)
                                if texts:
                                    _add_to_similar_cache(rid, texts)
                                    st.session_state["practice_current"] = {"handwriting_text": texts[0], "attachments": [], "record_id": ""}
                                    st.session_state["practice_is_similar"] = True
                                    st.session_state["practice_similar_count"] = 1
                                    st.rerun()
                                else:
                                    _go_next_practice()
                            except Exception as e:
                                st.error(f"ç”Ÿæˆç±»ä¼¼é¢˜ç›®å¤±è´¥ï¼š{e}")
                                _go_next_practice()
                    else:
                        _go_next_practice()
                else:
                    # ç¬¬äºŒæ¬¡ç‚¹å‡»"ä¸ä¼š"ï¼ˆåœ¨ç±»ä¼¼é¢˜ä¸Šï¼‰
                    cnt = st.session_state.get("practice_similar_count", 0)
                    if cnt < 2 and orig:
                        orig_rid = (orig.get("record_id") or "").strip()
                        # ä¼˜å…ˆä»ç¼“å­˜è·å–ç¬¬äºŒé“ç±»ä¼¼é¢˜
                        cached_second = _get_second_similar_from_cache(orig_rid)
                        if cached_second:
                            st.session_state["practice_current"] = {"handwriting_text": cached_second, "attachments": [], "record_id": ""}
                            st.session_state["practice_similar_count"] = 2
                            st.rerun()
                        elif llm_api_key:
                            with st.spinner("å†å‡ºä¸€é“ç±»ä¼¼é¢˜ç›®â€¦"):
                                try:
                                    texts = generate_similar_questions_with_llm(orig, 1, llm_api_key, llm_api_base, llm_model, token)
                                    if texts:
                                        st.session_state["practice_current"] = {"handwriting_text": texts[0], "attachments": [], "record_id": ""}
                                        st.session_state["practice_similar_count"] = 2
                                        st.rerun()
                                    else:
                                        _go_next_practice()
                            except Exception:
                                _go_next_practice()
                    else:
                        _go_next_practice()
                st.rerun()
    else:
        st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹ç»ƒä¹ ")
        if st.button("ğŸš€ å¼€å§‹ç»ƒä¹ ", type="primary", use_container_width=True, key="practice_start"):
            with st.spinner("æ­£åœ¨åŠ è½½ç»ƒä¹ è®°å½•â€¦"):
                try:
                    pm = fetch_practice_records(token, practice_table_id)
                    
                    # è¿‡æ»¤æ‰ä»Šæ—¥å·²ç»ƒè¿‡çš„é¢˜ç›®
                    available_questions = _filter_not_practiced_today(filtered_practice)
                    
                    n = pick_next_question(available_questions, pm, int(time.time() * 1000))
                    if not n:
                        st.info("æš‚æ— éœ€è¦å¤ä¹ çš„é¢˜ç›®ï¼Œæˆ–ä»Šæ—¥çš„é¢˜ç›®å·²å…¨éƒ¨ç»ƒå®Œã€‚")
                    else:
                        # ç«‹å³æ˜¾ç¤ºç¬¬ä¸€é“é¢˜
                        st.session_state["practice_current"] = n
                        st.session_state["practice_map"] = pm
                        st.session_state["practice_table_id"] = practice_table_id
                        st.session_state["practice_filtered"] = filtered_practice
                        st.session_state["practice_origin"] = None
                        st.session_state["practice_is_similar"] = False
                        st.session_state["practice_similar_count"] = 0
                        
                        # è®¾ç½®é¢„ç”Ÿæˆé˜Ÿåˆ—ï¼ˆæ‰€æœ‰å¯ç»ƒä¹ çš„é¢˜ç›®ï¼‰
                        st.session_state["pregenerate_queue"] = available_questions
                        st.session_state["pregenerate_done"] = set()
                        st.session_state["pregenerate_started"] = True
                        
                        st.rerun()
                except Exception as e:
                    st.error(f"åŠ è½½ç»ƒä¹ è®°å½•å¤±è´¥ï¼š{e}")
    
    # åå°é¢„ç”Ÿæˆé€»è¾‘ï¼šæ¯æ¬¡é¡µé¢åˆ·æ–°æ—¶å°è¯•ç”Ÿæˆä¸€é“
    if st.session_state.get("pregenerate_started") and llm_api_key:
        queue = st.session_state.get("pregenerate_queue", [])
        done = st.session_state.get("pregenerate_done", set())
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªéœ€è¦é¢„ç”Ÿæˆçš„é¢˜ç›®
        for q in queue:
            rid = (q.get("record_id") or "").strip()
            if rid and rid not in done:
                # é¢„ç”Ÿæˆè¿™é“é¢˜çš„ç±»ä¼¼é¢˜ï¼ˆä¸é˜»å¡UIï¼‰
                _pregenerate_one_similar(q, llm_api_key, llm_api_base, llm_model, token)
                break  # æ¯æ¬¡åªç”Ÿæˆä¸€é“ï¼Œé¿å…é˜»å¡å¤ªä¹…
    
    # åº•éƒ¨è¿”å›æŒ‰é’®
    st.markdown("---")
    if st.button("â† è¿”å›ä¸»é¡µ", key="practice_back_bottom"):
        for k in ("practice_current", "practice_origin", "practice_is_similar", "practice_similar_count", "practice_map", "practice_filtered", "practice_table_id", "pregenerate_queue", "pregenerate_done", "pregenerate_started"):
            st.session_state.pop(k, None)
        st.session_state["current_page"] = "home"
        st.rerun()


def _render_exam_page(token, records, llm_api_key, llm_api_base, llm_model):
    """æ¸²æŸ“ç”Ÿæˆè¯•å·é¡µé¢"""
    # è¿”å›æŒ‰é’®
    if st.button("â† è¿”å›ä¸»é¡µ", key="exam_back"):
        st.session_state["current_page"] = "home"
        st.rerun()
    
    st.title("ğŸ“„ ç”Ÿæˆè¯•å·")
    st.caption("é€‰æ‹©å­¦ç§‘å’ŒçŸ¥è¯†ç‚¹ï¼Œç”Ÿæˆé”™é¢˜ä¸“é¡¹è®­ç»ƒ")
    
    # å­¦ç§‘é€‰æ‹©
    subjects = sorted({r["subject"] for r in records if r.get("subject")})
    if not subjects:
        st.warning("æ²¡æœ‰æ‰¾åˆ°å­¦ç§‘æ•°æ®")
        return
    
    selected_subjects = st.multiselect("é€‰æ‹©å­¦ç§‘", options=subjects, default=subjects, key="exam_subjects")
    if not selected_subjects:
        st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªå­¦ç§‘")
        return
    
    filtered = [r for r in records if r.get("subject") in selected_subjects]
    
    # çŸ¥è¯†ç‚¹é€‰æ‹©
    knowledge_options = sorted({kp for r in filtered for kp in r.get("knowledge_points") or []})
    selected_kp = st.multiselect("é€‰æ‹©çŸ¥è¯†ç‚¹", options=knowledge_options, default=knowledge_options, key="exam_kp")
    
    # æ¯ä¸ªçŸ¥è¯†ç‚¹çš„é¢˜ç›®æ•°é‡
    selected_plan: Dict[str, int] = {}
    for kp in selected_kp:
        pool = [r for r in filtered if kp in (r.get("knowledge_points") or [])]
        max_count = len(pool)
        count = st.number_input(f"{kp}ï¼ˆæœ€å¤š {max_count} é¢˜ï¼‰", min_value=0, max_value=max_count, value=max_count, key=f"exam_count_{kp}")
        selected_plan[kp] = count
    
    # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ€»é¢˜ç›®æ•°é‡
    total_count = sum(selected_plan.values())
    st.markdown(f"### å½“å‰é€‰æ‹©é¢˜ç›®æ•°é‡ï¼š{total_count} é“")
    
    has_valid_selection = any(count > 0 for count in selected_plan.values())
    
    if not has_valid_selection:
        st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€é“é¢˜ç›®")
        return
    
    def prepare_selections():
        selections: Dict[str, List[Dict]] = {}
        for kp, count in selected_plan.items():
            if count <= 0:
                continue
            pool = [r for r in filtered if kp in (r.get("knowledge_points") or [])]
            if count > len(pool):
                count = len(pool)
            if count > 0:
                selections[kp] = random.sample(pool, count)
        return selections
    
    def prepare_similar_selections():
        similar_selections: Dict[str, List[Dict]] = {}
        total_upper = sum(c for c in selected_plan.values() if c > 0)
        progress_bar = st.progress(0.0) if total_upper > 0 else None
        current = 0
        
        for kp, count in selected_plan.items():
            if count <= 0:
                continue
            pool = [r for r in filtered if kp in (r.get("knowledge_points") or [])]
            if not pool:
                continue
            pool_with_time = [(r, r.get("created_time", 0)) for r in pool if r.get("handwriting_text") or r.get("attachments")]
            if not pool_with_time:
                continue
            pool_with_time.sort(key=lambda x: x[1], reverse=True)
            X = min(count, len(pool_with_time))
            reference_questions = [pool_with_time[i][0] for i in range(X)]
            
            generated_questions = []
            for ref in reference_questions:
                try:
                    texts = generate_similar_questions_with_llm(ref, 1, llm_api_key, llm_api_base, llm_model, token)
                    if texts:
                        generated_questions.append({
                            "subject": ref.get("subject"),
                            "knowledge_points": [kp],
                            "handwriting_text": texts[0],
                            "reason_type": "",
                            "reason_detail": "",
                            "attachments": [],
                            "created_time": 0,
                        })
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
                current += 1
                if progress_bar:
                    progress_bar.progress(min(1.0, current / total_upper))
            
            if generated_questions:
                similar_selections[kp] = generated_questions
        
        if progress_bar:
            progress_bar.progress(1.0)
        return similar_selections
    
    st.markdown("---")
    st.markdown("### ç”ŸæˆåŸé¢˜è¯•å·")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ç”Ÿæˆ Word æ–‡æ¡£", type="primary", use_container_width=True, key="exam_word"):
            try:
                progress_bar = st.progress(0, text="æ­£åœ¨å‡†å¤‡é¢˜ç›®...")
                selections = prepare_selections()
                if not selections:
                    st.warning("æ²¡æœ‰å¯ç”¨é¢˜ç›®")
                    return
                progress_bar.progress(30, text="æ­£åœ¨ç”Ÿæˆæ–‡æ¡£...")
                doc_bytes = build_doc(selected_subjects, selections, token)
                progress_bar.progress(100, text="ç”Ÿæˆå®Œæˆï¼")
                filename = f"{'ã€'.join(selected_subjects)}_åŸé¢˜è¯•å·.docx"
                st.success("âœ“ ç”ŸæˆæˆåŠŸ")
                st.download_button("ğŸ“¥ ä¸‹è½½ Word", data=doc_bytes, file_name=filename, mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
    
    with col2:
        if st.button("ç”Ÿæˆ HTML æ–‡æ¡£", type="primary", use_container_width=True, key="exam_html"):
            try:
                progress_bar = st.progress(0, text="æ­£åœ¨å‡†å¤‡é¢˜ç›®...")
                selections = prepare_selections()
                if not selections:
                    st.warning("æ²¡æœ‰å¯ç”¨é¢˜ç›®")
                    return
                progress_bar.progress(30, text="æ­£åœ¨ç”Ÿæˆæ–‡æ¡£...")
                html_content = build_html(selected_subjects, selections, token)
                progress_bar.progress(100, text="ç”Ÿæˆå®Œæˆï¼")
                filename = f"{'ã€'.join(selected_subjects)}_åŸé¢˜è¯•å·.html"
                st.success("âœ“ ç”ŸæˆæˆåŠŸ")
                st.download_button("ğŸ“¥ ä¸‹è½½ HTML", data=html_content.encode('utf-8'), file_name=filename, mime="text/html", use_container_width=True)
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
    
    st.markdown("---")
    st.markdown("### ç”Ÿæˆç±»ä¼¼é¢˜è¯•å·")
    
    if not llm_api_key:
        st.warning("âš ï¸ éœ€è¦é…ç½®æ™ºè°±AI API Key æ‰èƒ½ç”Ÿæˆç±»ä¼¼é¢˜ç›®")
    else:
        col3, col4 = st.columns(2)
        with col3:
            if st.button("ç”Ÿæˆç±»ä¼¼é¢˜ Word", type="primary", use_container_width=True, key="exam_similar_word"):
                try:
                    st.info("æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆç±»ä¼¼é¢˜ç›®ï¼Œè¯·ç¨å€™...")
                    similar_selections = prepare_similar_selections()
                    if not similar_selections:
                        st.warning("ç”Ÿæˆå¤±è´¥æˆ–æ²¡æœ‰å¯ç”¨é¢˜ç›®")
                        return
                    doc_bytes = build_doc(selected_subjects, similar_selections, token)
                    filename = f"{'ã€'.join(selected_subjects)}_ç±»ä¼¼é¢˜è¯•å·.docx"
                    st.success("âœ“ ç”ŸæˆæˆåŠŸ")
                    st.download_button("ğŸ“¥ ä¸‹è½½ Word", data=doc_bytes, file_name=filename, mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True, key="dl_similar_word")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
        
        with col4:
            if st.button("ç”Ÿæˆç±»ä¼¼é¢˜ HTML", type="primary", use_container_width=True, key="exam_similar_html"):
                try:
                    st.info("æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆç±»ä¼¼é¢˜ç›®ï¼Œè¯·ç¨å€™...")
                    similar_selections = prepare_similar_selections()
                    if not similar_selections:
                        st.warning("ç”Ÿæˆå¤±è´¥æˆ–æ²¡æœ‰å¯ç”¨é¢˜ç›®")
                        return
                    html_content = build_html(selected_subjects, similar_selections, token)
                    filename = f"{'ã€'.join(selected_subjects)}_ç±»ä¼¼é¢˜è¯•å·.html"
                    st.success("âœ“ ç”ŸæˆæˆåŠŸ")
                    st.download_button("ğŸ“¥ ä¸‹è½½ HTML", data=html_content.encode('utf-8'), file_name=filename, mime="text/html", use_container_width=True, key="dl_similar_html")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
    
    # åº•éƒ¨è¿”å›æŒ‰é’®
    st.markdown("---")
    if st.button("â† è¿”å›ä¸»é¡µ", key="exam_back_bottom"):
        st.session_state["current_page"] = "home"
        st.rerun()


def main() -> None:
    st.set_page_config(page_title="é”™é¢˜æœ¬", page_icon="ğŸ“š", layout="wide")
    
    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    if "current_page" not in st.session_state:
        st.session_state["current_page"] = "home"
    
    # åŠ è½½é…ç½®
    app_id, app_secret, llm_api_key, llm_api_base, llm_model, config, is_streamlit_cloud = _load_app_config()
    
    # æ£€æŸ¥å‡­æ®
    app_id, app_secret = _check_feishu_credentials(app_id, app_secret, is_streamlit_cloud)
    
    # ä¸»é¡µä¸éœ€è¦åŠ è½½æ•°æ®
    if st.session_state["current_page"] == "home":
        _render_home_page()
        return
    
    # å…¶ä»–é¡µé¢éœ€è¦åŠ è½½æ•°æ®
    try:
        token = get_tenant_access_token(app_id, app_secret)
        raw_records = fetch_records(token)
        records = parse_records(raw_records)
    except requests.exceptions.ConnectionError as exc:
        st.error(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼š{exc}")
        if st.button("è¿”å›ä¸»é¡µ"):
            st.session_state["current_page"] = "home"
            st.rerun()
        return
    except RuntimeError as exc:
        msg = str(exc)
        if "99991663" in msg:
            st.error("é£ä¹¦è®¿é—®ä»¤ç‰Œæ— æ•ˆï¼Œè¯·æ£€æŸ¥åº”ç”¨æƒé™é…ç½®")
        else:
            st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{exc}")
        if st.button("è¿”å›ä¸»é¡µ"):
            st.session_state["current_page"] = "home"
            st.rerun()
        return
    except Exception as exc:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥ï¼š{exc}")
        if st.button("è¿”å›ä¸»é¡µ"):
            st.session_state["current_page"] = "home"
            st.rerun()
        return
    
    if not records:
        st.warning("è¡¨æ ¼æš‚æ— è®°å½•ï¼Œè¯·å…ˆåœ¨é£ä¹¦å¤šç»´è¡¨æ ¼å¡«å……æ•°æ®ã€‚")
        if st.button("è¿”å›ä¸»é¡µ"):
            st.session_state["current_page"] = "home"
            st.rerun()
        return
    
    # æ ¹æ®å½“å‰é¡µé¢æ¸²æŸ“å†…å®¹
    if st.session_state["current_page"] == "practice":
        _render_practice_page(token, records, llm_api_key, llm_api_base, llm_model, config)
    elif st.session_state["current_page"] == "exam":
        _render_exam_page(token, records, llm_api_key, llm_api_base, llm_model)


if __name__ == "__main__":
    main()
